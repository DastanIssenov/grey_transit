import streamlit as st
import pandas as pd
from io import BytesIO
import zipfile

USER_CREDENTIALS = {
    "ktzh": "ktzhpass"
}

def login():
    st.title("üîí Login Required")
    with st.form("login_form"):
        username = st.text_input("Username")
        password = st.text_input("Password", type="password")
        submitted = st.form_submit_button("Login")

        if submitted:
            if USER_CREDENTIALS.get(username) == password:
                st.session_state.logged_in = True
                st.rerun()
            else:
                st.error("Invalid username or password")

# Initialize session state
if "logged_in" not in st.session_state:
    st.session_state.logged_in = False

if not st.session_state.logged_in:
    login()
    st.stop()

def convert_df_to_excel(df):
    output = BytesIO()
    with pd.ExcelWriter(output, engine='xlsxwriter') as writer:
        df.to_excel(writer, index=False, sheet_name='Grey Transit')
    output.seek(0)
    return output

def read_single_csv_from_zip(uploaded_file):
    with zipfile.ZipFile(uploaded_file) as z:
        # Get list of files that are not hidden/macOS junk
        valid_files = [f for f in z.namelist() if f.endswith('.csv') and '__MACOSX' not in f and not f.startswith('.')]
        if len(valid_files) != 1:
            raise ValueError(f"Expected 1 CSV file, found {len(valid_files)}: {valid_files}")
        return pd.read_csv(z.open(valid_files[0]))

st.set_page_config(page_title="Grey Transit Matcher", layout="wide")
st.title("üöÇ Grey Transit Data Processor")

st.subheader("1. Upload 3 Import and 3 Export `.csv.zip` Files")

# Upload zipped import files
im_10 = st.file_uploader("Upload Import File Q1 (.csv.zip)", type="zip", key="im10")
im_11 = st.file_uploader("Upload Import File Q2 (.csv.zip)", type="zip", key="im11")
im_12 = st.file_uploader("Upload Import File Q3 (.csv.zip)", type="zip", key="im12")

# Upload zipped export files
ex_10 = st.file_uploader("Upload Export File Q1 (.csv.zip)", type="zip", key="ex10")
ex_11 = st.file_uploader("Upload Export File Q2 (.csv.zip)", type="zip", key="ex11")
ex_12 = st.file_uploader("Upload Export File Q3 (.csv.zip)", type="zip", key="ex12")

# Proceed if all files are uploaded
if all([im_10, im_11, im_12, ex_10, ex_11, ex_12]):

    # Read zipped CSVs
    im_10_df = read_single_csv_from_zip(im_10)
    im_11_df = read_single_csv_from_zip(im_11)
    im_12_df = read_single_csv_from_zip(im_12)
    ex_10_df = read_single_csv_from_zip(ex_10)
    ex_11_df = read_single_csv_from_zip(ex_11)
    ex_12_df = read_single_csv_from_zip(ex_12)

    # Intersection and concat for export
    common_columns_ex = ex_10_df.columns.intersection(ex_11_df.columns).intersection(ex_12_df.columns)
    export_all = pd.concat([ex_10_df[common_columns_ex], ex_11_df[common_columns_ex], ex_12_df[common_columns_ex]], ignore_index=True)

    # Intersection and concat for import
    common_columns_im = im_10_df.columns.intersection(im_11_df.columns).intersection(im_12_df.columns)
    import_all = pd.concat([im_10_df[common_columns_im], im_11_df[common_columns_im], im_12_df[common_columns_im]], ignore_index=True)

    # --- Continue previous transformation ---
    


    common_columns_ex = ex_10_df.columns.intersection(ex_11_df.columns).intersection(ex_12_df.columns)
    export_all = pd.concat([ex_10_df[common_columns_ex], ex_11_df[common_columns_ex], ex_12_df[common_columns_ex]], ignore_index=True)


    common_columns_im = im_10_df.columns.intersection(im_11_df.columns).intersection(im_12_df.columns)
    import_all = pd.concat([im_10_df[common_columns_im], im_11_df[common_columns_im], im_12_df[common_columns_im]], ignore_index=True)

    import_all = import_all[import_all['–ù–∞–∏–º–µ–Ω–æ–≤–∞–Ω–∏–µ –ì–ü'].notna()]
    export_all = export_all[export_all['–ù–∞–∏–º–µ–Ω–æ–≤–∞–Ω–∏–µ –ì–ü'].notna()]
    import_all["–ù–∞–∏–º–µ–Ω–æ–≤–∞–Ω–∏–µ –ì–ü"] = import_all["–ù–∞–∏–º–µ–Ω–æ–≤–∞–Ω–∏–µ –ì–ü"].apply(lambda x: x.replace('–¢–û–í–ê–†–ò–©–ï–°–¢–í–û –° –û–ì–†–ê–ù–ò–ß–ï–ù–ù–û–ô –û–¢–í–ï–¢–°–¢–í–ï–ù–ù–û–°–¢–¨–Æ "QAZEXPOCENTRE - PIPE"', '–¢–û–û "QAZEXPOCENTRE - PIPE"'))
    export_all["–ù–∞–∏–º–µ–Ω–æ–≤–∞–Ω–∏–µ –ì–ü"] = export_all["–ù–∞–∏–º–µ–Ω–æ–≤–∞–Ω–∏–µ –ì–ü"].apply(lambda x: x.replace('–¢–û–í–ê–†–ò–©–ï–°–¢–í–û –° –û–ì–†–ê–ù–ò–ß–ï–ù–ù–û–ô –û–¢–í–ï–¢–°–¢–í–ï–ù–ù–û–°–¢–¨–Æ "QAZEXPOCENTRE - PIPE"', '–¢–û–û "QAZEXPOCENTRE - PIPE"'))



    import_df = import_all.copy()
    export_df = export_all.copy()


    import_df.rename(columns={"–í–µ—Å –Ω–∞ –≤–∞–≥–æ–Ω (–∫–≥)": "–í–µ—Å –Ω–∞ –≤–∞–≥–æ–Ω (–∫–≥)_x",
                                "–ö–æ–¥ –≥—Ä—É–∑–∞": "–ö–æ–¥ –≥—Ä—É–∑–∞_x",
                                "–ù–æ–º–µ—Ä –≤–∞–≥–æ–Ω–∞\\–∫–æ–Ω—Ç": "–ù–æ–º–µ—Ä –≤–∞–≥–æ–Ω–∞_x",
                                "–ù–∞–∏–º–µ–Ω–æ–≤–∞–Ω–∏–µ —Å—Ç–∞–Ω—Ü–∏–∏ –Ω–∞–∑–Ω–∞–µ–Ω–∏—è": "–ù–∞–∏–º–µ–Ω–æ–≤–∞–Ω–∏–µ —Å—Ç–∞–Ω—Ü–∏–∏ –Ω–∞–∑–Ω–∞—á–µ–Ω–∏—è"}, inplace=True)

    export_df.rename(columns={"–í–µ—Å –Ω–∞ –≤–∞–≥–æ–Ω (–∫–≥)": "–í–µ—Å –Ω–∞ –≤–∞–≥–æ–Ω (–∫–≥)_y",
                                "–ö–æ–¥ –≥—Ä—É–∑–∞": "–ö–æ–¥ –≥—Ä—É–∑–∞_y",
                                "–ù–æ–º–µ—Ä –≤–∞–≥–æ–Ω–∞\\–∫–æ–Ω—Ç": "–ù–æ–º–µ—Ä –≤–∞–≥–æ–Ω–∞_y"}, inplace = True)


    import_df = import_df[['–î–æ–∫—É–º–µ–Ω—Ç', '–ù–∞–∏–º–µ–Ω–æ–≤–∞–Ω–∏–µ –ì–û', '–ù–∞–∏–º–µ–Ω–æ–≤–∞–Ω–∏–µ –ì–ü', '–ù–∞–∏–º–µ–Ω–æ–≤–∞–Ω–∏–µ —Å—Ç—Ä–∞–Ω—ã –æ—Ç–ø—Ä–∞–≤–ª–µ–Ω–∏—è',
                            "–ù–∞–∏–º–µ–Ω–æ–≤–∞–Ω–∏–µ —Å—Ç–∞–Ω—Ü–∏–∏ –æ—Ç–ø—Ä–∞–≤–ª–µ–Ω–∏—è", "–°—Ç–∞–Ω—Ü–∏—è –æ—Ç–ø—Ä–∞–≤–ª–µ–Ω–∏—è", "–ù–∞–∏–º–µ–Ω–æ–≤–∞–Ω–∏–µ —Å—Ç—Ä–∞–Ω—ã –Ω–∞–∑–Ω–∞—á–µ–Ω–∏—è",
                            "–ù–∞–∏–º–µ–Ω–æ–≤–∞–Ω–∏–µ —Å—Ç–∞–Ω—Ü–∏–∏ –Ω–∞–∑–Ω–∞—á–µ–Ω–∏—è", '–°—Ç–∞–Ω—Ü–∏—è –Ω–∞–∑–Ω–∞—á–µ–Ω–∏—è', "–ù–æ–º–µ—Ä –≤–∞–≥–æ–Ω–∞_x",
                            '–û–±—â–∏–π –≤–µ—Å –ø–æ –¥–æ–∫—É–º–µ–Ω—Ç—É (–∫–≥)', '–í–µ—Å –Ω–∞ –≤–∞–≥–æ–Ω (–∫–≥)_x', '–ö–æ–¥ –≥—Ä—É–∑–∞_x', '–ù–∞–∏–º–µ–Ω–æ–≤–∞–Ω–∏–µ –≥—Ä—É–∑–∞',
                            '–ö–æ–¥ –≥—Ä—É–∑–æ–ø–æ–ª—É—á–∞—Ç–µ–ª—è', '–î–∞—Ç–∞ –ø—Ä–∏–±—ã—Ç–∏—è', '–í–∑—ã—Å–∫–∞–Ω–æ –ø–æ –ø—Ä–∏–±—ã—Ç–∏—é (–ø–æ—Å–ª–µ–¥–Ω–∏–µ 2 –∑–Ω–∞–∫–∞ —Ç–∏—ã–Ω—ã)']]

    export_df = export_df[['–î–æ–∫—É–º–µ–Ω—Ç', "–ù–∞–∏–º–µ–Ω–æ–≤–∞–Ω–∏–µ –ì–û", "–ù–∞–∏–º–µ–Ω–æ–≤–∞–Ω–∏–µ –ì–ü", '–ù–∞–∏–º–µ–Ω–æ–≤–∞–Ω–∏–µ —Å—Ç—Ä–∞–Ω—ã –æ—Ç–ø—Ä–∞–≤–ª–µ–Ω–∏—è',
                            "–ù–∞–∏–º–µ–Ω–æ–≤–∞–Ω–∏–µ —Å—Ç–∞–Ω—Ü–∏–∏ –æ—Ç–ø—Ä–∞–≤–ª–µ–Ω–∏—è", "–°—Ç–∞–Ω—Ü–∏—è –æ—Ç–ø—Ä–∞–≤–ª–µ–Ω–∏—è", "–ù–∞–∏–º–µ–Ω–æ–≤–∞–Ω–∏–µ —Å—Ç—Ä–∞–Ω—ã –Ω–∞–∑–Ω–∞—á–µ–Ω–∏—è",
                            "–ù–∞–∏–º–µ–Ω–æ–≤–∞–Ω–∏–µ —Å—Ç–∞–Ω—Ü–∏–∏ –Ω–∞–∑–Ω–∞—á–µ–Ω–∏—è", '–°—Ç–∞–Ω—Ü–∏—è –Ω–∞–∑–Ω–∞—á–µ–Ω–∏—è', "–ù–æ–º–µ—Ä –≤–∞–≥–æ–Ω–∞_y",
                            '–û–±—â–∏–π –≤–µ—Å –ø–æ –¥–æ–∫—É–º–µ–Ω—Ç—É (–∫–≥)', '–í–µ—Å –Ω–∞ –≤–∞–≥–æ–Ω (–∫–≥)_y', '–ö–æ–¥ –≥—Ä—É–∑–∞_y', '–ù–∞–∏–º–µ–Ω–æ–≤–∞–Ω–∏–µ –≥—Ä—É–∑–∞',
                            '–ö–æ–¥ –≥—Ä—É–∑–æ–æ—Ç–ø—Ä–∞–≤–∏—Ç–µ–ª—è', '–î–∞—Ç–∞ –æ—Ç–ø—Ä–∞–≤–ª–µ–Ω–∏—è',
                            '–í–∑—ã—Å–∫–∞–Ω–æ –ø—Ä–∏ –æ—Ç–ø—Ä–∞–≤–ª–µ–Ω–∏—è  (–ø–æ—Å–ª–µ–¥–Ω–∏–µ 2 –∑–Ω–∞–∫–∞ —Ç–∏—ã–Ω—ã)']]



    import_df['–î–∞—Ç–∞ –ø—Ä–∏–±—ã—Ç–∏—è'] = pd.to_datetime(import_df['–î–∞—Ç–∞ –ø—Ä–∏–±—ã—Ç–∏—è'], dayfirst=True, errors='coerce')
    export_df['–î–∞—Ç–∞ –æ—Ç–ø—Ä–∞–≤–ª–µ–Ω–∏—è'] = pd.to_datetime(export_df['–î–∞—Ç–∞ –æ—Ç–ø—Ä–∞–≤–ª–µ–Ω–∏—è'], dayfirst=True, errors='coerce')

    merged = pd.merge(
        import_df,
        export_df,
        left_on=['–ù–æ–º–µ—Ä –≤–∞–≥–æ–Ω–∞_x', '–ù–∞–∏–º–µ–Ω–æ–≤–∞–Ω–∏–µ –ì–ü', '–°—Ç–∞–Ω—Ü–∏—è –Ω–∞–∑–Ω–∞—á–µ–Ω–∏—è', "–í–µ—Å –Ω–∞ –≤–∞–≥–æ–Ω (–∫–≥)_x"],
        right_on=['–ù–æ–º–µ—Ä –≤–∞–≥–æ–Ω–∞_y', '–ù–∞–∏–º–µ–Ω–æ–≤–∞–Ω–∏–µ –ì–û', '–°—Ç–∞–Ω—Ü–∏—è –æ—Ç–ø—Ä–∞–≤–ª–µ–Ω–∏—è', "–í–µ—Å –Ω–∞ –≤–∞–≥–æ–Ω (–∫–≥)_y"],
        how='inner'
    )

    merged = merged[merged['–ù–∞–∏–º–µ–Ω–æ–≤–∞–Ω–∏–µ —Å—Ç—Ä–∞–Ω—ã –æ—Ç–ø—Ä–∞–≤–ª–µ–Ω–∏—è_x'] != merged['–ù–∞–∏–º–µ–Ω–æ–≤–∞–Ω–∏–µ —Å—Ç—Ä–∞–Ω—ã –Ω–∞–∑–Ω–∞—á–µ–Ω–∏—è_y']]
    merged = merged[merged['–î–∞—Ç–∞ –ø—Ä–∏–±—ã—Ç–∏—è'] <= merged['–î–∞—Ç–∞ –æ—Ç–ø—Ä–∞–≤–ª–µ–Ω–∏—è']]
    merged = merged[merged["–í–µ—Å –Ω–∞ –≤–∞–≥–æ–Ω (–∫–≥)_x"] != 0]

    grey_transit = merged.copy()

    st.success(f"‚úÖ Successfully matched {len(grey_transit)} rows.")

    st.subheader("2. Preview of Merged Grey Transit Data")
    st.dataframe(grey_transit, use_container_width=True)

    st.subheader("3. Download Result")
    
    excel_file = convert_df_to_excel(grey_transit)
    st.download_button(
        label="üì• Download Grey Transit Excel",
        data=excel_file,
        file_name="grey_transit_quarter_2024_Q4.xlsx",
        mime="application/vnd.openxmlformats-officedocument.spreadsheetml.sheet",
    )

    # except Exception as e:
    #     st.error(f"‚ö†Ô∏è Error while processing files: {e}")
else:
    st.info("üëÜ Please upload all 6 files to continue.")
